{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNy3nhE0XM/cRw9dlSM5oha",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mhmmd-Mhmmd/Quera_questions/blob/main/06_transfer_learning_scaling_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf5h-N8WGbwG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com./ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
        "zip_ref = zipfile.ZipFile(file='./101_food_classes_10_percent.zip')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n",
        "!rm 101_food_classes_10_percent.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdwjm5Ka094b",
        "outputId": "cab9e142-2eaf-4391-cd2d-d92a3cc68e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-08 07:34:23--  https://storage.googleapis.com./ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com. (storage.googleapis.com.)... 142.251.2.207, 74.125.137.207, 2607:f8b0:4023:c0d::cf, ...\n",
            "Connecting to storage.googleapis.com. (storage.googleapis.com.)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1625420029 (1.5G) [application/zip]\n",
            "Saving to: ‘101_food_classes_10_percent.zip’\n",
            "\n",
            "101_food_classes_10 100%[===================>]   1.51G   109MB/s    in 14s     \n",
            "\n",
            "2023-10-08 07:34:37 (110 MB/s) - ‘101_food_classes_10_percent.zip’ saved [1625420029/1625420029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(directory='./101_food_classes_10_percent/train/',\n",
        "                                                                 batch_size=32,\n",
        "                                                                 image_size=(224, 224),\n",
        "                                                                 shuffle=True,\n",
        "                                                                 label_mode='categorical')\n",
        "\n",
        "valid_data = tf.keras.preprocessing.image_dataset_from_directory(directory='./101_food_classes_10_percent/test/',\n",
        "                                                                 batch_size=32,\n",
        "                                                                 label_mode='categorical',\n",
        "                                                                 shuffle=False,\n",
        "                                                                 image_size=(224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQxegEE61Zzj",
        "outputId": "e82527eb-a671-4c58-bcba-409ac59b52f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7575 files belonging to 101 classes.\n",
            "Found 25250 files belonging to 101 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential(layers=[tf.keras.layers.experimental.preprocessing.RandomFlip(),\n",
        "                                                tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "                                                tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "                                                tf.keras.layers.experimental.preprocessing.RandomHeight(0.2),\n",
        "                                                tf.keras.layers.experimental.preprocessing.RandomWidth(0.2),\n",
        "                                                tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),], # & rescaling layer for cases like resnet\n",
        "                                        name='augmentation_layer')"
      ],
      "metadata": {
        "id": "2o_b3oZ44Rxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name='input_layer')\n",
        "\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name='vectorizing_layer')(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(units=len(train_data.class_names), activation=tf.keras.activations.softmax, name='classifier')(x)\n",
        "\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_0.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                metrics='accuracy')\n",
        "\n",
        "model_0_history_featute = model_0.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_steps=int(0.25 * len(valid_data)),\n",
        "    epochs=5,\n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/model_0/featue/',\n",
        "                                              write_images=True),\n",
        "                tf.keras.callbacks.ModelCheckpoint(filepath='checkpoints/model_0/featue/model_0_feature.ckpt',\n",
        "                                                    save_best_only=True,\n",
        "                                                    save_weights_only=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7ShBasT3tsJ",
        "outputId": "941708b2-4c62-45d4-8cab-a6fceadf408e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "237/237 [==============================] - 129s 480ms/step - loss: 3.4905 - accuracy: 0.2519 - val_loss: 2.6289 - val_accuracy: 0.4132\n",
            "Epoch 2/5\n",
            "237/237 [==============================] - 88s 371ms/step - loss: 2.3722 - accuracy: 0.4549 - val_loss: 2.1374 - val_accuracy: 0.4865\n",
            "Epoch 3/5\n",
            "237/237 [==============================] - 79s 331ms/step - loss: 2.0066 - accuracy: 0.5267 - val_loss: 1.9664 - val_accuracy: 0.5049\n",
            "Epoch 4/5\n",
            "237/237 [==============================] - 68s 287ms/step - loss: 1.7926 - accuracy: 0.5632 - val_loss: 1.8633 - val_accuracy: 0.5260\n",
            "Epoch 5/5\n",
            "237/237 [==============================] - 69s 288ms/step - loss: 1.6423 - accuracy: 0.5914 - val_loss: 1.8246 - val_accuracy: 0.5252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_feature = model_0.evaluate(valid_data)\n",
        "result_feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd3PI-07NVBt",
        "outputId": "cbc8e7e6-5aad-4d39-91fe-2e9c2d053a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790/790 [==============================] - 58s 74ms/step - loss: 1.7093 - accuracy: 0.5522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7092682123184204, 0.5521584153175354]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_0.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), # 10X lesses\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                metrics='accuracy')\n",
        "\n",
        "model_0_history_fine = model_0.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_steps=int(0.25 * len(valid_data)),\n",
        "    epochs=10,\n",
        "    initial_epoch=model_0_history_featute.epoch[-1],\n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/model_0/fine/',\n",
        "                                              write_images=True),\n",
        "                tf.keras.callbacks.ModelCheckpoint(filepath='checkpoints/model_0/fine/model_0_fine.ckpt',\n",
        "                                                    save_best_only=True,\n",
        "                                                    save_weights_only=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtfMLF--Be8m",
        "outputId": "65db99d2-46e8-4388-fe05-41f67d0e9f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10\n",
            "237/237 [==============================] - 73s 279ms/step - loss: 1.4782 - accuracy: 0.6465 - val_loss: 1.8152 - val_accuracy: 0.5295\n",
            "Epoch 6/10\n",
            "237/237 [==============================] - 59s 246ms/step - loss: 1.4439 - accuracy: 0.6511 - val_loss: 1.8085 - val_accuracy: 0.5317\n",
            "Epoch 7/10\n",
            "237/237 [==============================] - 57s 236ms/step - loss: 1.4391 - accuracy: 0.6540 - val_loss: 1.8052 - val_accuracy: 0.5343\n",
            "Epoch 8/10\n",
            "237/237 [==============================] - 55s 232ms/step - loss: 1.4341 - accuracy: 0.6552 - val_loss: 1.8033 - val_accuracy: 0.5332\n",
            "Epoch 9/10\n",
            "237/237 [==============================] - 58s 246ms/step - loss: 1.4131 - accuracy: 0.6586 - val_loss: 1.8005 - val_accuracy: 0.5338\n",
            "Epoch 10/10\n",
            "237/237 [==============================] - 57s 238ms/step - loss: 1.4049 - accuracy: 0.6619 - val_loss: 1.7923 - val_accuracy: 0.5336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_fine = model_0.evaluate(valid_data)\n",
        "result_fine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnuMs7GoNhzI",
        "outputId": "f8bec677-6c9c-41a4-e5db-f07924c8b962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790/790 [==============================] - 60s 76ms/step - loss: 1.6576 - accuracy: 0.5641\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6575735807418823, 0.5641188025474548]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name='input_layer')\n",
        "\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name='vectorizer')(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(units=len(train_data.class_names), activation='softmax', name='classifier')(x)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                metrics='accuracy')\n",
        "\n",
        "model_1_history_feature = model_1.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=valid_data,\n",
        "    validation_steps=int(0.25*len(valid_data)),\n",
        "    epochs=5,\n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/model_1_feature/',\n",
        "                                              write_graph=True,\n",
        "                                              write_images=True),\n",
        "               tf.keras.callbacks.ModelCheckpoint(filepath='checkpoints/model_1_feature.ckpt',\n",
        "                                                  save_weights_only=True,\n",
        "                                                  save_best_only=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oegcyV-UYBu",
        "outputId": "69092b58-548e-4707-a6c3-42db499d2be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "237/237 [==============================] - 233s 892ms/step - loss: 3.4402 - accuracy: 0.2399 - val_loss: 2.5932 - val_accuracy: 0.3834\n",
            "Epoch 2/5\n",
            "237/237 [==============================] - 210s 886ms/step - loss: 2.4511 - accuracy: 0.4169 - val_loss: 2.1916 - val_accuracy: 0.4535\n",
            "Epoch 3/5\n",
            "237/237 [==============================] - 207s 874ms/step - loss: 2.1315 - accuracy: 0.4821 - val_loss: 2.0694 - val_accuracy: 0.4743\n",
            "Epoch 4/5\n",
            "237/237 [==============================] - 189s 798ms/step - loss: 1.9610 - accuracy: 0.5141 - val_loss: 1.9999 - val_accuracy: 0.4894\n",
            "Epoch 5/5\n",
            "237/237 [==============================] - 201s 846ms/step - loss: 1.8171 - accuracy: 0.5450 - val_loss: 1.9210 - val_accuracy: 0.5005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_model_1_feature = model_1.evaluate(valid_data)\n",
        "results_model_1_feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MvlISV0bXcf",
        "outputId": "d9a83a0b-042c-4c2a-bcac-9dd4fae9526a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790/790 [==============================] - 294s 372ms/step - loss: 1.7830 - accuracy: 0.5409\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7829984426498413, 0.5409108996391296]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                metrics='accuracy')\n",
        "\n",
        "model_1_history_fine = model_1.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=valid_data,\n",
        "    validation_steps=int(0.25*len(valid_data)),\n",
        "    epochs=10,\n",
        "    initial_epoch=model_1_history_feature.epoch[-1],\n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs/model_1_fine/',\n",
        "                                              write_graph=True,\n",
        "                                              write_images=True),\n",
        "               tf.keras.callbacks.ModelCheckpoint(filepath='checkpoints/model_1_fine.ckpt',\n",
        "                                                  save_weights_only=True,\n",
        "                                                  save_best_only=True)])"
      ],
      "metadata": {
        "id": "jt1mNW2Max3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f866696-5527-450a-f600-2e8261c5da83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10\n",
            "237/237 [==============================] - 226s 862ms/step - loss: 1.6603 - accuracy: 0.5876 - val_loss: 1.9132 - val_accuracy: 0.5087\n",
            "Epoch 6/10\n",
            "237/237 [==============================] - 186s 783ms/step - loss: 1.6139 - accuracy: 0.6000 - val_loss: 1.9085 - val_accuracy: 0.5098\n",
            "Epoch 7/10\n",
            "237/237 [==============================] - 185s 780ms/step - loss: 1.6078 - accuracy: 0.6028 - val_loss: 1.8980 - val_accuracy: 0.5127\n",
            "Epoch 8/10\n",
            "237/237 [==============================] - 197s 828ms/step - loss: 1.5992 - accuracy: 0.6078 - val_loss: 1.8963 - val_accuracy: 0.5108\n",
            "Epoch 9/10\n",
            "237/237 [==============================] - 185s 776ms/step - loss: 1.5890 - accuracy: 0.6032 - val_loss: 1.8840 - val_accuracy: 0.5165\n",
            "Epoch 10/10\n",
            "237/237 [==============================] - 190s 801ms/step - loss: 1.5774 - accuracy: 0.6137 - val_loss: 1.8807 - val_accuracy: 0.5174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_model_1_fine = model_1.evaluate(valid_data)\n",
        "results_model_1_fine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD3o0gUQbbhl",
        "outputId": "2661591f-3073-4fd8-e9e0-99c7b91580fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790/790 [==============================] - 293s 371ms/step - loss: 1.7307 - accuracy: 0.5531\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7306791543960571, 0.5530692934989929]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_prep_images(filename: srt, image_shape=(224, 224), scale=True):\n",
        "    img = tf.io.read_file(filename)\n",
        "    img = tg.io.decode_image(image, channels=30)\n",
        "    img = tf.image.resize(img, imahe_shape)\n",
        "\n",
        "    if scale:\n",
        "        return img/225.\n",
        "    else:\n",
        "        return img"
      ],
      "metadata": {
        "id": "Kn2xAowobrog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bW5bFzQloKmL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}